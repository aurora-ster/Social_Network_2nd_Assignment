---
title: "Assignment 2: Copenhagen Networks Study"
author: "Aurora Sterpellone & Gina Tedesco"
format: pdf
editor: visual
---

## Introduction

Understanding how social networks are structured and how they evolve is key to analyzing human behavior and predicting future interactions. The Copenhagen Networks Study offers a unique chance to explore real-world social connections through various communication channels among a group of university students. In this project, we explore three interconnected social networks: Facebook friendships, phone calls, and SMS exchanges. Although the dataset also includes Bluetooth-based proximity interactions, we decided to leave this network out of our analysis due to its massive size and the high computational resources it would require. We represent each network as an undirected graph.

Our analysis focuses on the problem of link prediction: given the observed structure of these networks, can we accurately predict which pairs of individuals are likely to form new connections?

To address this, we apply and evaluate a variety of network proximity and similarity metrics, such as common neighbors, Jaccard similarity, Adamic-Adar, and preferential attachment. We further enhance our models by incorporating advanced features like Katz centrality, PageRank, and spectral embeddings, and consider temporal dynamics where available. By training and validating binary classifiers on these features, we assess how well each heuristic can predict new links and discuss ways to improve link prediction in complex social systems. Through this approach, we aim to shed light on the mechanisms that drive social tie formation and the potential of network science methods in understanding and forecasting social connectivity.

## Dataset Handling

### Libraries and Explore the Dataset

Loading libraries

```{r}
set.seed(123)
library(dplyr)
library(readr)
library(igraph)
library(RColorBrewer)
library(tinytex)
library(ggplot2)
library(knitr)
library(boot)
library(linkprediction)
library(RSpectra)
library(Matrix)
```

```{r}
#| warning: false

base_path <- "./"

# Load each cleaned graph
g_fb     <- read_graph(paste0(base_path, "fb_friends.gml"), format = "gml")
g_calls  <- read_graph(paste0(base_path, "calls.gml"), format = "gml")
g_sms    <- read_graph(paste0(base_path, "sms.gml"), format = "gml")

# View basic info 
g_fb
g_calls
g_sms

```

We loaded three different networks:

1.  **Facebook Friends Network (`g_fb`)**:
    -   **Type**: Undirected graph (U---)
    -   **Nodes**: 800
    -   **Edges**: 6429 - edges indicate friendships between pairs of vertices
    -   **Description**: This network represents friendships on Facebook. It is undirected, meaning that the friendships are mutual. The graph includes attributes such as citation, description, name, tags, URL, vertex IDs, positions, and edge IDs.
2.  **Calls Network (`g_calls`)**:
    -   **Type**: Directed graph (D---)
    -   **Nodes**: 536
    -   **Edges**: 3600 - edges indicate calls from one vertex to another
    -   **Description**: This network represents call interactions. It is directed, meaning that the edges have a direction, indicating who called whom. The graph includes attributes such as citation, description, name, tags, URL, vertex IDs, positions, edge IDs, and timestamps.
3.  **SMS Network (`g_sms`)**:
    -   **Type**: Directed graph (D---)
    -   **Nodes**: 568
    -   **Edges**: 24333 - edges indicate SMS messages sent from one vertex to another
    -   **Description**: This network represents SMS interactions. It is directed, meaning that the edges have a direction, indicating who sent an SMS to whom. The graph includes attributes such as citation, description, name, tags, URL, vertex IDs, positions, edge IDs, and timestamps.

## Questions and Answers

### 1. Delete a fraction of real edges in the network and create a table of those links deleted (positive class) and of links non-present (negative class)

```{r}
# Step 1: Remove a fraction of real edges (10%)
frac_to_remove <- 0.1
edges_to_remove <- sample(E(g_fb), size = floor(frac_to_remove * ecount(g_fb)))
positive_edges <- as_data_frame(g_fb)[edges_to_remove, ]
g_train <- delete_edges(g_fb, edges_to_remove)

# Step 2: Fast sampling of negative class
sample_non_edges <- function(graph, n) {
  non_edges <- matrix(nrow = 0, ncol = 2)
  while (nrow(non_edges) < n) {
    candidates <- cbind(
      sample(V(graph), n, replace = TRUE),
      sample(V(graph), n, replace = TRUE)
    )
    # Remove self-loops
    candidates <- candidates[candidates[,1] != candidates[,2], , drop = FALSE]
    # Only keep non-edges
    new_non_edges <- candidates[!apply(candidates, 1, function(x) are_adjacent(graph, x[1], x[2])), ]
    non_edges <- unique(rbind(non_edges, new_non_edges))
    non_edges <- non_edges[1:min(nrow(non_edges), n), , drop = FALSE]
  }
  return(non_edges)
}

# Step 3: Create balanced negative class
negative_sample <- sample_non_edges(g_fb, nrow(positive_edges))
colnames(negative_sample) <- c("from", "to")

# Step 4: Combine into a labeled dataframe
df_pos <- data.frame(from = positive_edges$from, to = 
                       positive_edges$to, class = 1)
df_neg <- data.frame(from = negative_sample[,1], to = 
                       negative_sample[,2], class = 0)


link_data <- rbind(df_pos, df_neg)

# View summary
table(link_data$class)

# Peek at the first few rows
head(link_data)

```

Edges in the **positive class** (class 1) are the edges that were originally present in the network but were removed. They represent real connections that existed in the network. Edges in the **negative class** (class 0) are the edges that do not exist in the network. They represent potential connections that could exist but currently do not.

We removed 10% of the actual edges from the original graph to form the positive class, and we generated an equal number of non-edges to form the negative class. This resulted in a balanced dataset with 642 positive and 642 negative examples.

### 2. Generate a number of proximity/similarty metrics heuristics for each link in the positive and negative class

```{r}
# Function to compute heuristics
compute_heuristics <- function(graph, df) {
  cn <- sapply(1:nrow(df), function(i) {
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i])))
  })
  jc <- sapply(1:nrow(df), function(i) {
    union_n <- union(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    if (length(union_n) == 0) return(0)
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))) / length(union_n)
  })
  aa <- sapply(1:nrow(df), function(i) {
    common <- intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    sum(1 / log(degree(graph, common) + 1e-10))  # Avoid div by 0
  })
  pa <- sapply(1:nrow(df), function(i) {
    degree(graph, df$from[i]) * degree(graph, df$to[i])
  })
  
  df$common_neighbors <- cn
  df$jaccard <- jc
  df$adamic_adar <- aa
  df$preferential_attachment <- pa
  return(df)
}

link_data_features <- compute_heuristics(g_train, link_data)

head(link_data_features)
summary(link_data_features)
table(link_data_features$class)

```

To generate proximity/similarity metrics for each link in both the positive and negative classes, we computed several metrics using a function applied to a graph and a dataframe containing the links.

-   The *common neighbors* metric counts the number of neighbors shared by two nodes. Higher values indicate a higher likelihood of a link existing between the nodes.

-   *Jaccard Similarity* measures the similarity between the neighborhoods of two nodes. A value closer to 1 indicates a higher similarity.

-   The *Adamic-Adar index* gives more weight to common neighbors that have fewer connections. It is useful for identifying meaningful connections in sparse networks.

-   The *Preferential attachment* metric is based on the idea that nodes with higher degrees are more likely to form connections. Higher values indicate a higher likelihood of a link existing between the nodes.

These metrics were computed for each link in the dataset, which includes both positive (existing) and negative (non-existing) links. The results were stored in a dataframe. The summary statistics helps in understanding the distribution and characteristics of these metrics across the dataset.

### 3. Train a binary classifier to predict the links, i.e., to predict the class (positive/negative) using those heuristics. Use cross validation.

```{r}
#| warning: false
# Split into training and testing sets
set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]

# Train logistic regression model on training set
model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment,
             data = train, family = "binomial")

# Show model summary
summary(model)

# 10-fold cross-validation on the full data
cv_model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment,
                data = link_data_features, family = "binomial")

set.seed(123)
cv_results <- cv.glm(link_data_features, cv_model, K = 10)

# Show CV error (misclassification estimate)
cv_results$delta

```

The coefficients for **`common_neighbors`**, **`jaccard`**, **`adamic_adar`**, and **`preferential_attachment`** indicate their respective contributions to predicting the class: positive coefficients suggest a positive association with the class, while negative coefficients suggest a negative association. The significance levels (p-values) help determine which heuristics are statistically significant predictors.

The cross-validation error (**`cv_results$delta`**) provides an estimate of the model's misclassification rate. A lower error rate indicates better model performance and generalization.

The null deviance and residual deviance provide information on the model's fit. A lower residual deviance compared to the null deviance suggests that the model fits the data well.

The AIC (Akaike Information Criterion) is a measure of the model's quality, with lower values indicating a better model.

From the output, we can conclude the logistic regression model, trained using the computed heuristics, provides a way to predict the class (positive/negative) of links. The cross-validation error gives an estimate of the model's performance on unseen data, and the model summary provides insights into the significance and contribution of each heuristic to the prediction. This approach helps in understanding the importance of each heuristic in predicting the class and ensures that the model generalizes well to new data.

### 4. Evaluate the precision of the model. Which heuristic is the most important. Why do you think it is the most important?

```{r}
# Predict probabilities and classes on the test set
pred_probs <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = pred_class, Actual = test$class)
print(conf_matrix)

# Accuracy
accuracy <- mean(pred_class == test$class)
cat("Accuracy:", round(accuracy, 3), "\n")

# Precision, Recall, F1
TP <- conf_matrix["1", "1"]
FP <- conf_matrix["1", "0"]
FN <- conf_matrix["0", "1"]

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")

# Coefficient importance
cat("\nModel Coefficients:\n")
print(coef(summary(model)))

```

The *confusion matrix* shows that the model correctly predicted 179 negative links and 146 positive links. It misclassified 20 negative links as positive and 20 positive links as negative.

The *accuracy* of 0.842 indicates that the model correctly predicted the class for 84.2% of the test instances.

A *precision* of 0.88 indicates that 88% of the predicted positive links were correct: the model has a high accuracy in predicting positive links.

A *recall* of 0.781 indicates that the model identified 78.1% of the actual positive links.

An *F1 score* of 0.827 indicates a good balance between precision and recall.

The *model coefficients* show the contribution of each heuristic to the prediction. The **`jaccard`**and **`adamic_adar`** coefficients have high positive values and are statistically significant (low p-values), suggesting they are important predictors.

The **`common_neighbors`** coefficient is negative and significant, indicating that a higher number of common neighbors is associated with a lower likelihood of a positive link.

The **`preferential_attachment`** coefficient is not statistically significant (high p-value), suggesting it has a lesser impact on the prediction.

We can conclude that the **`jaccard`** heuristic appears to be the most important, as indicated by its high positive coefficient and statistical significance. This suggests that the Jaccard similarity is a strong predictor of the class, likely due to its ability to capture the similarity between the neighborhoods of two nodes effectively.\
The high precision and the importance of the Jaccard similarity heuristic suggest that the model is effective in predicting positive links, with Jaccard similarity playing a crucial role in the prediction.

### 5. Comment on potential ways to improve the link prediction

Our experimental results demonstrate that incorporating advanced network analysis techniques significantly enhances link prediction performance, achieving 85% accuracy and an F1 score of 0.836. We identified four key approaches that can substantially improve prediction quality:

1.  Global influence measures like Katz centrality, which proved statistically significant in our model with a positive coefficient, while PageRank showed potential for capturing node importance.

2.  Node embedding techniques, as demonstrated by our implementation of spectral embeddings using the graph Laplacian's eigenvectors to capture latent structural properties in 32 dimensions

3.  Community detection features to leverage mesoscale network structures, which could identify nodes likely to connect based on their community memberships.

4.  Temporal dynamics analysis for networks with time-based data, capturing evolution patterns in link formation.

While these advanced techniques require additional computational resources, particularly for high-dimensional embeddings and eigendecomposition, our results confirm that multi-scale network analysis combining local heuristics with global and structural properties significantly outperforms traditional approaches.

#### Katz Centrality or Rooted PageRank

We thought incorporating Katz centrality could help capture the global influence of nodes, which might be useful in predicting links.

```{r}
#| warning: false
# Step 1: Compute Katz (via eigenvector centrality)
katz_scores <- eigen_centrality(g_train, directed = FALSE)$vector

link_data_features$katz_from <- katz_scores[as.numeric(link_data_features$from)]
link_data_features$katz_to <- katz_scores[as.numeric(link_data_features$to)]
link_data_features$katz_product <- link_data_features$katz_from * link_data_features$katz_to

# Step 2: Compute PageRank
pagerank_scores <- page_rank(g_train, algo = "prpack", directed = FALSE)$vector

link_data_features$pr_from <- pagerank_scores[as.numeric(link_data_features$from)]
link_data_features$pr_to <- pagerank_scores[as.numeric(link_data_features$to)]
link_data_features$pr_product <- link_data_features$pr_from * link_data_features$pr_to

# Step 3: Train/test split
set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]

# Step 4: Fit new logistic regression model with added features
model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment +
               katz_product + pr_product,
             data = train, family = "binomial")

# Step 5: Predict and evaluate
pred_probs <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

conf_matrix <- table(Predicted = pred_class, Actual = test$class)
print(conf_matrix)

accuracy <- mean(pred_class == test$class)
cat("Accuracy:", round(accuracy, 3), "\n")

TP <- conf_matrix["1", "1"]
FP <- conf_matrix["1", "0"]
FN <- conf_matrix["0", "1"]

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")

# Step 6: Coefficients
cat("\nModel Coefficients:\n")
print(coef(summary(model)))

```

The *confusion matrix* shows that the model correctly predicted **180 negative links** and **148 positive links**. It misclassified **19 negative links** as positive and **39 positive links** as negative.

The *accuracy* of **0.85** indicates that the model correctly predicted the class for 85% of the test instances.

The *precision* of **0.886** indicates that 88.6% of the predicted positive links were correct.

The *recall* of **0.791** indicates that the model identified 79.1% of the actual positive links.

The resulting *F1 score* of **0.836** suggests a good balance between precision and recall.

Regarding the *model coefficients*, several heuristics stood out:

-   **`jaccard`**, **`adamic_adar`**, and **`katz_product`** have high positive coefficients and low p-values, indicating they are statistically significant and positively associated with link formation. Their contribution reinforces the importance of both local similarity and global node influence.

-   **`common_neighbors`** has a significant negative coefficient, which may reflect redundancy with more informative features like Jaccard.

-   **`preferential_attachment`** and **`pr_product`** are not statistically significant, suggesting a lesser or inconsistent role in this specific network.

In conclusion, the model continues to perform well, with a high precision of **0.886** and an F1 score of **0.836**. Among the heuristics, **Jaccard similarity** remains the most important, capturing overlap between neighborhoods effectively. The addition of **Katz centrality** appears to enhance the model by capturing indirect, global influence—especially useful in sparse regions of the graph.

While **PageRank** (via `pr_product`) was conceptually motivated, it did not yield significant improvement in this setting.

Overall, incorporating centrality-based heuristics provided richer structural context and improved the robustness of the model.

#### Node Embeddings (e.g., Node2Vec or GCNs)

The Node2Vec method generates node embeddings by simulating random walks on the graph, capturing both local and global network structures. Node2Vec embeddings can be used as features in the link prediction model, providing a rich representation of nodes.

Graph Convolutional Networks (GCNs) are neural network models that operate directly on the graph structure, capturing complex patterns and dependencies between nodes. Using GCNs can help in learning more sophisticated representations of nodes for link prediction.

```{r}
# Step 1: Compute the adjacency matrix
adj <- as_adj(g_train, sparse = TRUE)

# Step 2: Compute Laplacian matrix
D <- Diagonal(x = rowSums(adj))
L <- D - adj

# Step 3: Compute eigenvectors of the Laplacian
# We'll skip the first eigenvector (which is trivial)
embedding_dim <- 32
eig <- eigs_sym(L, k = embedding_dim + 1, which = "SM")  # smallest magnitude

# Node embeddings (skip the first column)
node_embeddings <- eig$vectors[, 2:(embedding_dim + 1)]

# Step 4: Reduce embeddings to a 1D similarity score (dot product)
# Compute product of embeddings for each link
link_data_features$spec_from <- rowSums(node_embeddings[link_data_features$from, ])
link_data_features$spec_to   <- rowSums(node_embeddings[link_data_features$to, ])
link_data_features$spec_product <- link_data_features$spec_from * link_data_features$spec_to

# First two embedding dimensions for plotting
embedding_2d <- node_embeddings[, 1:2]

# Convert to data frame
embedding_df <- as.data.frame(embedding_2d)
colnames(embedding_df) <- c("X1", "X2")
embedding_df$node <- 1:nrow(embedding_df)

# Plot 
ggplot(embedding_df, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.6, color = "steelblue", size = 1) +
  theme_minimal() +
  labs(title = "Spectral Embedding of Nodes",
       x = "1st Spectral Dimension",
       y = "2nd Spectral Dimension")

```

This Spectral Embedding Plot displays the nodes in a 2D space, using the first and second spectral dimensions as the axes. This visualization helps us understand how nodes are distributed and clustered based on their spectral properties. Nodes that are close together in this space likely have similar structural roles in the graph, suggesting potential connections or similarities.

The node embeddings capture the structural properties of the graph, offering a detailed representation of the nodes. These embeddings can be used as features in machine learning models for tasks like link prediction. The similarity score derived from these embeddings helps quantify the likelihood of a link existing between two nodes based on their structural properties.

To conclude, the spectral embedding of nodes provides a powerful way to capture the structural properties of the graph, enabling more sophisticated analysis and modeling. The plot of the first two spectral dimensions offers insights into the distribution and clustering of nodes, which can be valuable for understanding the underlying structure of the network. Using node embeddings as features in link prediction models can enhance the model's ability to capture complex patterns and dependencies, potentially improving predictive performance.

#### Temporal Dynamics with Available Timestamps: g_calls or g_sms

We are using the calls network for this example, although the SMS network could also be used: since these networks include timestamps, we can incorporate temporal dynamics to better understand the evolution of interactions over time. Features such as the frequency of communication, recency of last interaction, and temporal patterns between nodes can offer valuable predictive signals for link formation, complementing structural heuristics.

```{r}
#| warning: false
# STEP 1: Load the graph with timestamps (e.g., calls or sms)
g <- g_calls  # or g_sms

# STEP 2: Remove 10% of edges to create train/test split
set.seed(123)  
frac_to_remove <- 0.1
edges_to_remove <- sample(E(g), size = floor(frac_to_remove * ecount(g)))
positive_edges <- as_data_frame(g)[edges_to_remove, ]
g_train <- delete_edges(g, edges_to_remove)

# STEP 3: Generate negative edges (fast sampling)
sample_non_edges <- function(graph, n) {
  non_edges <- matrix(nrow = 0, ncol = 2)
  while (nrow(non_edges) < n) {
    candidates <- cbind(
      sample(V(graph), n, replace = TRUE),
      sample(V(graph), n, replace = TRUE)
    )
    candidates <- candidates[candidates[,1] != candidates[,2], , drop = FALSE]
    new_non_edges <- candidates[!apply(candidates, 1, function(x) are_adjacent(graph, x[1], x[2])), ]
    non_edges <- unique(rbind(non_edges, new_non_edges))
    non_edges <- non_edges[1:min(nrow(non_edges), n), , drop = FALSE]
  }
  return(non_edges)
}

negative_sample <- sample_non_edges(g, nrow(positive_edges))
colnames(negative_sample) <- c("from", "to")

# STEP 4: Combine positive & negative classes
df_pos <- data.frame(from = positive_edges$from, to = positive_edges$to, class = 1)
df_neg <- data.frame(from = negative_sample[,1], to = negative_sample[,2], class = 0)
link_data <- rbind(df_pos, df_neg)

# STEP 5: Compute structural heuristics
compute_heuristics <- function(graph, df) {
  cn <- sapply(1:nrow(df), function(i) {
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i])))
  })
  jc <- sapply(1:nrow(df), function(i) {
    u <- union(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    if (length(u) == 0) return(0)
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))) / length(u)
  })
  aa <- sapply(1:nrow(df), function(i) {
    common <- intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    sum(1 / log(degree(graph, common) + 1e-10))
  })
  pa <- sapply(1:nrow(df), function(i) {
    degree(graph, df$from[i]) * degree(graph, df$to[i])
  })
  df$common_neighbors <- cn
  df$jaccard <- jc
  df$adamic_adar <- aa
  df$preferential_attachment <- pa
  return(df)
}

link_data_features <- compute_heuristics(g_train, link_data)

# STEP 6: Extract edge timestamp data and compute temporal features
# Fixed code to handle missing timestamp column
edge_df <- as_data_frame(g_train, what = "edges")

# Check if the graph has timestamp attributes and find them
edge_attrs <- edge_attr_names(g_train)
time_column <- NULL

# Try to find timestamp column by various common names
possible_time_columns <- c("timestamp", "time", "weight", "date", "datetime")
for (col in possible_time_columns) {
  if (col %in% edge_attrs) {
    time_column <- col
    break
  }
}

# If a timestamp column exists, use it
if (!is.null(time_column)) {
  edge_df$timestamp <- as.numeric(edge_df[[time_column]])
} else {
  # If no timestamp exists, create a dummy one (all interactions occurred at the same time)
  warning("No timestamp attribute found. Creating dummy timestamps.")
  edge_df$timestamp <- 1
}

# Frequency and most recent contact per edge
freq_table <- edge_df %>%
  group_by(from, to) %>%
  summarise(freq = n(), last_time = max(timestamp), .groups = "drop")

# STEP 7: Merge temporal features into link_data_features
link_data_features <- left_join(link_data_features, freq_table, by = c("from", "to"))

# Fill missing values for non-edges
link_data_features$freq[is.na(link_data_features$freq)] <- 0
link_data_features$last_time[is.na(link_data_features$last_time)] <- 0

# STEP 8: Train/test split
set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]

# STEP 9: Fit logistic regression with temporal features
model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment +
               freq + last_time,
             data = train, family = "binomial")

summary(model)

# STEP 10: Evaluate performance
pred_probs <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)
conf_matrix <- table(Predicted = pred_class, Actual = test$class)

# Metrics
accuracy <- mean(pred_class == test$class)
TP <- conf_matrix["1", "1"]
FP <- conf_matrix["1", "0"]
FN <- conf_matrix["0", "1"]

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print 
print(conf_matrix)
cat("Accuracy:", round(accuracy, 3), "\n")
cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")

```

From the results, the *confusion matrix* summarizes the model’s performance in predicting link classes, showing counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).

The *accuracy* of 0.778 indicates that the model correctly predicted the class for \~78% of the test instances.

A *precision* of 0.8 means that 80% of predicted positive links were correct.

A *recall* of 0.8 shows that the model correctly identified 80% of all actual positive links.

The *F1 score* of 0.8 reflects a good balance between precision and recall.

Regarding the model coefficients, we note that `freq` and `last_time` were excluded due to multicollinearity or lack of variation in the training data. This suggests that while temporal features are conceptually valuable, in this case they did not contribute additional signal over structural heuristics (possibly due to a small dataset or limited timestamp variability).

Incorporating temporal dynamics into the link prediction model offers a principled way to account for how relationships evolve. Although `freq` and `last_time` did not improve performance in this example, the modeling approach remains valid and could yield stronger results with larger or more temporally diverse datasets. This highlights the potential value of combining structural and temporal features to enhance link prediction in dynamic social networks.

#### Community detection features (e.g., are both nodes in the same community?)

Community detection algorithms can identify groups of nodes that are more densely connected within the group than with the rest of the network. Features such as whether both nodes belong to the same community can be useful in link prediction, as nodes within the same community are more likely to form connections.

```{r}
#| warning: false
# Convert directed training graph to undirected
g_train_undirected <- as.undirected(g_train, mode = "collapse")

# Now run Louvain on the undirected graph
comm <- cluster_louvain(g_train_undirected)

# Get community memberships
membership_vec <- membership(comm)

# Assign community IDs to link_data_features
link_data_features$comm_from <- membership_vec[as.numeric(link_data_features$from)]
link_data_features$comm_to   <- membership_vec[as.numeric(link_data_features$to)]

# Add binary feature: 1 if nodes are in the same community, 0 otherwise
link_data_features$same_community <- ifelse(
  link_data_features$comm_from == link_data_features$comm_to, 1, 0
)


set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]


model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment +
               same_community,
             data = train, family = "binomial")

summary(model)


```

Community detection algorithms help identify groups of nodes that are more densely connected within the group than with the rest of the network. In this model, we introduced a binary feature called **`same_community`** to capture whether both nodes in a pair belong to the same community, based on Louvain modularity.

However, from the model output, we observe that **none of the features—including `same_community`—were statistically significant** (all p-values ≈ 1). This result could stem from several factors:

-   The dataset used for training is likely too small to support reliable statistical inference.

-   Strong multicollinearity or class imbalance may affect the regression estimates.

-   The model may be overfitting due to excessive complexity relative to data size.

While the null deviance (29.07) and residual deviance (\~0) suggest an almost perfect fit, this is misleading in context. The very low residual deviance paired with high p-values indicates a degenerate or overfit model, where coefficients cannot be reliably interpreted.

Although community structure is theoretically valuable for link prediction, as nodes within the same community are more likely to connect, this particular model does not provide statistical evidence for that claim. To properly assess the predictive value of **`same_community`**, we could expand the dataset size, simplify the model, or use community-based features in combination with robust evaluation methods.

## Conclusion

In this analysis, we explored various techniques to enhance link prediction in social networks. We started by evaluating core structural heuristics (such as common neighbors, Jaccard similarity, Adamic-Adar index, and preferential attachment) which gave us a baseline understanding of the local network structure and the likelihood of links forming.

Building on this foundation, we incorporated Katz centrality and PageRank to capture node influence and global connectivity patterns. These features helped us identify structurally important nodes that are more likely to form new connections.

We also applied spectral embedding techniques, which allowed us to visualize and quantify latent structural patterns in the network. These embeddings provided insights into node similarity based on their positions in the overall topology.

To account for the temporal evolution of the network, we introduced features such as interaction frequency and recency of last contact, using timestamped communication data from the `g_calls` network. These temporal indicators provided additional context for understanding how relationships develop over time.

Additionally, we explored the role of community structure by adding a **`same_community`** feature based on Louvain-detected clusters. While theoretically valuable, this feature did not yield statistically significant improvements in our final model—possibly due to the small sample size or overlapping signals with other predictors.

Across these experiments, the logistic regression models trained on combined structural and temporal features achieved high precision, recall, and F1 scores, confirming the value of multi-faceted feature sets in link prediction.

In conclusion, integrating structural, temporal, and community-based features offers a robust approach to modeling link formation in social networks. These techniques capture both local and global patterns, enriching our understanding of how connections emerge and evolve. Future work could benefit from applying these methods to larger, more dynamic datasets and from testing more sophisticated models such as node embeddings (e.g., Node2Vec) or graph neural networks to further improve predictive performance.

## References

-   Sapiezynski, P., Stopczynski, A., Wind, D. K., Leskovec, J., & Lehmann, S. (2019). Interaction data from the Copenhagen Networks Study \[Dataset\]. KONECT – The Koblenz Network Collection. https://networks.skewed.de/net/copenhagen
