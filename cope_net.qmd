---
title: "Assignment 2: Copenhagen Networks Study"
author: "Aurora Sterpellone & Gina Tedesco"
format: pdf
editor: visual
---

## Introduction

Understanding the structure and dynamics of social networks is fundamental to analyzing human behavior and predicting future interactions. The Copenhagen Networks Study provides a unique opportunity to explore real-world social connectivity through multiple communication channels among a cohort of university students. In this project, we investigate three distinct but overlapping social networks: Facebook friendships, phone calls, and SMS exchanges. We represent each as an undirected graph. Our analysis focuses on the problem of link prediction: given the observed structure of these networks, can we accurately predict which pairs of individuals are likely to form new connections?

To address this, we systematically apply and evaluate a range of network proximity and similarity metrics, such as common neighbors, Jaccard similarity, Adamic-Adar, and preferential attachment. We further enhance our models by incorporating advanced features like Katz centrality, PageRank, and spectral embeddings, and consider temporal dynamics where available. By training and validating binary classifiers on these features, we assess the predictive power of each heuristic and discuss strategies for improving link prediction in complex social systems. Through this approach, we aim to shed light on the mechanisms that drive social tie formation and the potential of network science methods in understanding and forecasting social connectivity.

## Dataset Handling

### Libraries and Explore the Dataset

Loading libraries

```{r}
set.seed(123)
library(dplyr)
library(readr)
library(igraph)
library(RColorBrewer)
library(tinytex)
library(ggplot2)
library(knitr)
library(boot)
library(linkprediction)
library(RSpectra)
library(Matrix)
```

```{r}
#| warning: false

base_path <- "./"

# Load each cleaned graph
g_fb     <- read_graph(paste0(base_path, "fb_friends.gml"), format = "gml")
g_calls  <- read_graph(paste0(base_path, "calls.gml"), format = "gml")
g_sms    <- read_graph(paste0(base_path, "sms.gml"), format = "gml")

# View basic info (optional)
g_fb
g_calls
g_sms

```

We loaded three different networks:

1.  **Facebook Friends Network (`g_fb`)**:
    -   **Type**: Undirected graph (U---)
    -   **Vertices**: 800
    -   **Edges**: 6429 - edges indicate friendships between pairs of vertices
    -   **Description**: This network represents friendships on Facebook. It is undirected, meaning that the friendships are mutual. The graph includes attributes such as citation, description, name, tags, URL, vertex IDs, positions, and edge IDs.
2.  **Calls Network (`g_calls`)**:
    -   **Type**: Directed graph (D---)
    -   **Vertices**: 536
    -   **Edges**: 3600 - edges indicate calls from one vertex to another
    -   **Description**: This network represents call interactions. It is directed, meaning that the edges have a direction, indicating who called whom. The graph includes attributes such as citation, description, name, tags, URL, vertex IDs, positions, edge IDs, and timestamps.
3.  **SMS Network (`g_sms`)**:
    -   **Type**: Directed graph (D---)
    -   **Vertices**: 568
    -   **Edges**: 24333 - edges indicate SMS messages sent from one vertex to another
    -   **Description**: This network represents SMS interactions. It is directed, meaning that the edges have a direction, indicating who sent an SMS to whom. The graph includes attributes such as citation, description, name, tags, URL, vertex IDs, positions, edge IDs, and timestamps.

### Manual Similarity Metrics (Exploratory Example)

To demonstrate understanding of the core proximity metrics discussed in class, we apply a function to compute common neighbors, Jaccard similarity, Adamic-Adar, and preferential attachment for two selected nodes across three different networks: Facebook Friends, Calls, and SMS. This function is applied to each network to calculate and display these metrics. Additionally, we visualize the shortest path between the selected nodes in each network, highlighting the nodes and edges involved in the path.

```{r}
# Function to compute similarity metrics for two nodes in any graph
compute_manual_metrics <- function(g, v1, v2, network_name = "network") {
  nei_v1 <- neighbors(g, v1)
  nei_v2 <- neighbors(g, v2)
  
  common <- intersect(nei_v1, nei_v2)
  length_common <- length(common)
  
  jaccard <- length(common) / length(union(nei_v1, nei_v2))
  degrees_common <- degree(g, common)
  adamic_adar <- sum(1 / log(degrees_common + 1e-10))  # avoid div by 0
  pref_attach <- degree(g, v1) * degree(g, v2)
  
  cat("-----", network_name, "-----\n")
  cat("Nodes:", v1, "and", v2, "\n")
  cat("Common Neighbors:", length_common, "\n")
  cat("Jaccard:", round(jaccard, 3), "\n")
  cat("Adamic-Adar:", round(adamic_adar, 3), "\n")
  cat("Preferential Attachment:", pref_attach, "\n\n")
}

# Choose nodes (same for all networks if valid)
v1 <- 1
v2 <- 34

# Run for all 3 networks
compute_manual_metrics(g_fb, v1, v2, "Facebook Friends")
compute_manual_metrics(g_calls, v1, v2, "Calls")
compute_manual_metrics(g_sms, v1, v2, "SMS")


# Function to compute metrics and plot graph between v1 and v2
compute_and_plot <- function(g, v1, v2, title = "Network") {
  if (v1 > vcount(g) || v2 > vcount(g)) {
    cat("Skipping", title, "- nodes out of range\n")
    return()
  }
  
  nei_v1 <- neighbors(g, v1)
  nei_v2 <- neighbors(g, v2)
  common <- intersect(nei_v1, nei_v2)
  
  jaccard <- length(common) / length(union(nei_v1, nei_v2))
  degrees_common <- degree(g, common)
  adamic_adar <- sum(1 / log(degrees_common + 1e-10))
  pref_attach <- degree(g, v1) * degree(g, v2)
  
  cat("-----", title, "-----\n")
  cat("Nodes:", v1, "and", v2, "\n")
  cat("Common Neighbors:", length(common), "\n")
  cat("Jaccard:", round(jaccard, 3), "\n")
  cat("Adamic-Adar:", round(adamic_adar, 3), "\n")
  cat("Preferential Attachment:", pref_attach, "\n\n")
  
  # Plot
  ll <- layout_with_fr(g)
  V(g)$color <- "white"
  E(g)$color <- "lightgray"
  V(g)$color[c(v1, v2)] <- "orange"
  V(g)$color[common] <- "cyan"
  
  sp <- shortest_paths(g, from = v1, to = v2)$vpath[[1]]
  if (length(sp) > 0) {
    E(g, path = sp)$color <- "red"
  }
  
  plot(g,
       layout = ll,
       vertex.label = NA,
       vertex.size = 5,
       main = paste("Shortest path between", v1, "and", v2, "in", title))
}

# Run for all 3 networks
v1 <- 1
v2 <- 34

compute_and_plot(g_fb, v1, v2, "Facebook Friends")
compute_and_plot(g_calls, v1, v2, "Calls")
compute_and_plot(g_sms, v1, v2, "SMS")


```

These visualizations help in understanding the structural properties of each network and the relationships between the selected nodes.

The **Facebook Friends Network** show a dense cluster of nodes, indicating a highly interconnected network. [The shortest path between nodes 1 and 34 is highlighted in red, showing the direct connections between these nodes]{.underline}. Nodes 1 and 34 are colored in orange, and their common neighbors are colored in cyan, providing a visual representation of their proximity within the network.

The **Calls Network** graph appears more spread out compared to the Facebook Friends network, indicating a less dense connectivity. [The shortest path between nodes 1 and 34 is again highlighted in red.]{.underline} The orange and cyan nodes represent the selected nodes and their common neighbors, respectively, showing their interaction within the call network.

Finally, the **SMS Network** also shows a spread-out structure, indicating varied connectivity. [The shortest path between nodes 1 and 34 is highlighted in red.]{.underline} The orange and cyan nodes indicate the selected nodes and their common neighbors, illustrating their proximity in the SMS network.

## Questions and Answers

#### 1. Delete a fraction of real edges in the network and create a table of those links deleted (positive class) and of links non-present (negative class)

```{r}
# Step 1: Remove a fraction of real edges (10%)
frac_to_remove <- 0.1
edges_to_remove <- sample(E(g_fb), size = floor(frac_to_remove * ecount(g_fb)))
positive_edges <- as_data_frame(g_fb)[edges_to_remove, ]
g_train <- delete_edges(g_fb, edges_to_remove)

# Step 2: Fast sampling of negative class
sample_non_edges <- function(graph, n) {
  non_edges <- matrix(nrow = 0, ncol = 2)
  while (nrow(non_edges) < n) {
    candidates <- cbind(
      sample(V(graph), n, replace = TRUE),
      sample(V(graph), n, replace = TRUE)
    )
    # Remove self-loops
    candidates <- candidates[candidates[,1] != candidates[,2], , drop = FALSE]
    # Only keep non-edges
    new_non_edges <- candidates[!apply(candidates, 1, function(x) are_adjacent(graph, x[1], x[2])), ]
    non_edges <- unique(rbind(non_edges, new_non_edges))
    non_edges <- non_edges[1:min(nrow(non_edges), n), , drop = FALSE]
  }
  return(non_edges)
}

# Step 3: Create balanced negative class
negative_sample <- sample_non_edges(g_fb, nrow(positive_edges))
colnames(negative_sample) <- c("from", "to")

# Step 4: Combine into a labeled dataframe
df_pos <- data.frame(from = positive_edges$from, to = 
                       positive_edges$to, class = 1)
df_neg <- data.frame(from = negative_sample[,1], to = 
                       negative_sample[,2], class = 0)


link_data <- rbind(df_pos, df_neg)

# View summary
table(link_data$class)

# Peek at the first few rows
head(link_data)

```

The table of classes shows a balanced dataset with equal numbers of positive and negative samples.

Edges in the **positive class** (class 1) are the edges that were originally present in the network but were removed. They represent real connections that existed in the network. Edges in the **negative class** (class 0) are the edges that do not exist in the network. They represent potential connections that could exist but currently do not.

The dataset is balanced with an equal number of positive and negative samples, which is useful for training machine learning models where class imbalance can be an issue.

#### 2. Generate a number of proximity/similarty metrics heuristics for each link in the positive and negative class

```{r}
# Function to compute heuristics
compute_heuristics <- function(graph, df) {
  cn <- sapply(1:nrow(df), function(i) {
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i])))
  })
  jc <- sapply(1:nrow(df), function(i) {
    union_n <- union(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    if (length(union_n) == 0) return(0)
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))) / length(union_n)
  })
  aa <- sapply(1:nrow(df), function(i) {
    common <- intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    sum(1 / log(degree(graph, common) + 1e-10))  # Avoid div by 0
  })
  pa <- sapply(1:nrow(df), function(i) {
    degree(graph, df$from[i]) * degree(graph, df$to[i])
  })
  
  df$common_neighbors <- cn
  df$jaccard <- jc
  df$adamic_adar <- aa
  df$preferential_attachment <- pa
  return(df)
}

link_data_features <- compute_heuristics(g_train, link_data)

head(link_data_features)
summary(link_data_features)
table(link_data_features$class)

```

To generate proximity/similarity metrics for each link in both the positive and negative classes, we computed several metrics using a function applied to a graph and a dataframe containing the links.

-   The *common neighbors* metric counts the number of neighbors shared by two nodes. Higher values indicate a higher likelihood of a link existing between the nodes.

-   *Jaccard Similarity* measures the similarity between the neighborhoods of two nodes. A value closer to 1 indicates a higher similarity.

-   The *Adamic-Adar index* gives more weight to common neighbors that have fewer connections. It is useful for identifying meaningful connections in sparse networks.

-   The *Preferential attachment* metric is based on the idea that nodes with higher degrees are more likely to form connections. Higher values indicate a higher likelihood of a link existing between the nodes.

These metrics were computed for each link in the dataset, which includes both positive (existing) and negative (non-existing) links. The results were stored in a dataframe, providing a comprehensive set of proximity metrics for further analysis or machine learning tasks. The summary statistics helps in understanding the distribution and characteristics of these metrics across the dataset.

#### 3. Train a binary classifier to predict the links, i.e., to predict the class (positive/negative) using those heuristics. Use cross validation.

```{r}
#| warning: false
# Load required package
library(boot)

# Split into training and testing sets
set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]

# Train logistic regression model on training set
model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment,
             data = train, family = "binomial")

# Show model summary
summary(model)

# 10-fold cross-validation on the full data
cv_model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment,
                data = link_data_features, family = "binomial")

set.seed(123)
cv_results <- cv.glm(link_data_features, cv_model, K = 10)

# Show CV error (misclassification estimate)
cv_results$delta

```

The coefficients for **`common_neighbors`**, **`jaccard`**, **`adamic_adar`**, and **`preferential_attachment`** indicate their respective contributions to predicting the class. Positive coefficients suggest a positive association with the class, while negative coefficients suggest a negative association. The significance levels (p-values) help determine which heuristics are statistically significant predictors.

The cross-validation error (**`cv_results$delta`**) provides an estimate of the model's misclassification rate. A lower error rate indicates better model performance and generalization.

The null deviance and residual deviance provide information on the model's fit. A lower residual deviance compared to the null deviance suggests that the model fits the data well.

The AIC (Akaike Information Criterion) is a measure of the model's quality, with lower values indicating a better model.

We can conclude the logistic regression model, trained using the computed heuristics, provides a way to predict the class (positive/negative) of links. The cross-validation error gives an estimate of the model's performance on unseen data, and the model summary provides insights into the significance and contribution of each heuristic to the prediction. This approach helps in understanding the importance of each heuristic in predicting the class and ensures that the model generalizes well to new data.

#### 4. Evaluate the precision of the model. Which heuristic is the most important. Why do you think it is the most important?

```{r}
# Predict probabilities and classes on the test set
pred_probs <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(Predicted = pred_class, Actual = test$class)
print(conf_matrix)

# Accuracy
accuracy <- mean(pred_class == test$class)
cat("Accuracy:", round(accuracy, 3), "\n")

# Precision, Recall, F1
TP <- conf_matrix["1", "1"]
FP <- conf_matrix["1", "0"]
FN <- conf_matrix["0", "1"]

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")

# Coefficient importance
cat("\nModel Coefficients:\n")
print(coef(summary(model)))



```

The *confusion matrix* shows that the model correctly predicted 179 negative links and 154 positive links. It misclassified 33 negative links as positive and 20 positive links as negative.

The *accuracy* of 0.863 indicates that the model correctly predicted the class for 86.3% of the test instances.

A *precision* of 0.885 indicates that 88.5% of the predicted positive links were correct.

A *recall* of 0.824 indicates that the model identified 82.4% of the actual positive links.

An *F1 score* of 0.853 indicates a good balance between precision and recall.

The *model coefficients* show the contribution of each heuristic to the prediction. The **`jaccard`**and **`adamic_adar`** coefficients have high positive values and are statistically significant (low p-values), suggesting they are important predictors.

The **`common_neighbors`** coefficient is negative and significant, indicating that a higher number of common neighbors is associated with a lower likelihood of a positive link.

The **`preferential_attachment`** coefficient is not statistically significant (high p-value), suggesting it has a lesser impact on the prediction.

In conclusion, the precision of 0.885 indicates that the model has a high accuracy in predicting positive links.\
The **`jaccard`** heuristic appears to be the most important, as indicated by its high positive coefficient and statistical significance. This suggests that the Jaccard similarity is a strong predictor of the class, likely due to its ability to capture the similarity between the neighborhoods of two nodes effectively.\
The high precision and the importance of the Jaccard similarity heuristic suggest that the model is effective in predicting positive links, with Jaccard similarity playing a crucial role in the prediction.

#### 5. Comment on potential ways to improve the link prediction

```{r}
#*From Chatgpt*

#*To improve link prediction, we could include more complex features such as:*

# *Katz centrality or rooted PageRank*
# *Node embeddings (e.g., Node2Vec or GCNs)*
# Temporal dynamics if timestamps were available: calls or sms
# *Community detection features (e.g., are both nodes in the same community?)*

#From Gina
#I ended up feeling ambitious and recreated parts of the exercise for each of the suggestions Chatgpt gave. 

```

##### Katz Centrality or Rooted PageRank

```{r}
# Step 1: Compute Katz (via eigenvector centrality)
katz_scores <- eigen_centrality(g_train, directed = FALSE)$vector

link_data_features$katz_from <- katz_scores[as.numeric(link_data_features$from)]
link_data_features$katz_to <- katz_scores[as.numeric(link_data_features$to)]
link_data_features$katz_product <- link_data_features$katz_from * link_data_features$katz_to

# Step 2: Compute PageRank
pagerank_scores <- page_rank(g_train, algo = "prpack", directed = FALSE)$vector

link_data_features$pr_from <- pagerank_scores[as.numeric(link_data_features$from)]
link_data_features$pr_to <- pagerank_scores[as.numeric(link_data_features$to)]
link_data_features$pr_product <- link_data_features$pr_from * link_data_features$pr_to

# Step 3: Train/test split
set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]

# Step 4: Fit new logistic regression model with added features
model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment +
               katz_product + pr_product,
             data = train, family = "binomial")

# Step 5: Predict and evaluate
pred_probs <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

conf_matrix <- table(Predicted = pred_class, Actual = test$class)
print(conf_matrix)

accuracy <- mean(pred_class == test$class)
cat("Accuracy:", round(accuracy, 3), "\n")

TP <- conf_matrix["1", "1"]
FP <- conf_matrix["1", "0"]
FN <- conf_matrix["0", "1"]

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")

# Step 6: Coefficients
cat("\nModel Coefficients:\n")
print(coef(summary(model)))

```

##### Node embeddings (e.g., Node2Vec or GCNs)

```{r}
# Step 1: Compute the adjacency matrix
adj <- as_adj(g_train, sparse = TRUE)

# Step 2: Compute Laplacian matrix
D <- Diagonal(x = rowSums(adj))
L <- D - adj

# Step 3: Compute eigenvectors of the Laplacian
# We'll skip the first eigenvector (which is trivial)
embedding_dim <- 32
eig <- eigs_sym(L, k = embedding_dim + 1, which = "SM")  # smallest magnitude

# Node embeddings (skip the first column)
node_embeddings <- eig$vectors[, 2:(embedding_dim + 1)]

# Step 4: Reduce embeddings to a 1D similarity score (dot product)
# Compute product of embeddings for each link
link_data_features$spec_from <- rowSums(node_embeddings[link_data_features$from, ])
link_data_features$spec_to   <- rowSums(node_embeddings[link_data_features$to, ])
link_data_features$spec_product <- link_data_features$spec_from * link_data_features$spec_to

# First two embedding dimensions for plotting
embedding_2d <- node_embeddings[, 1:2]

# Convert to data frame
embedding_df <- as.data.frame(embedding_2d)
colnames(embedding_df) <- c("X1", "X2")
embedding_df$node <- 1:nrow(embedding_df)

# Plot using ggplot2
library(ggplot2)

ggplot(embedding_df, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.6, color = "steelblue", size = 1) +
  theme_minimal() +
  labs(title = "Spectral Embedding of Nodes",
       x = "1st Spectral Dimension",
       y = "2nd Spectral Dimension")



```

##### Temporal dynamics if timestamps were available: calls or sms

```{r}
# STEP 1: Load the graph with timestamps (e.g., calls or sms)
g <- g_calls  # or g_sms

# STEP 2: Remove 10% of edges to create train/test split
frac_to_remove <- 0.1
edges_to_remove <- sample(E(g), size = floor(frac_to_remove * ecount(g)))
positive_edges <- as_data_frame(g)[edges_to_remove, ]
g_train <- delete_edges(g, edges_to_remove)

# STEP 3: Generate negative edges (fast sampling)
sample_non_edges <- function(graph, n) {
  non_edges <- matrix(nrow = 0, ncol = 2)
  while (nrow(non_edges) < n) {
    candidates <- cbind(
      sample(V(graph), n, replace = TRUE),
      sample(V(graph), n, replace = TRUE)
    )
    candidates <- candidates[candidates[,1] != candidates[,2], , drop = FALSE]
    new_non_edges <- candidates[!apply(candidates, 1, function(x) are_adjacent(graph, x[1], x[2])), ]
    non_edges <- unique(rbind(non_edges, new_non_edges))
    non_edges <- non_edges[1:min(nrow(non_edges), n), , drop = FALSE]
  }
  return(non_edges)
}

negative_sample <- sample_non_edges(g, nrow(positive_edges))
colnames(negative_sample) <- c("from", "to")

# STEP 4: Combine positive & negative classes
df_pos <- data.frame(from = positive_edges$from, to = positive_edges$to, class = 1)
df_neg <- data.frame(from = negative_sample[,1], to = negative_sample[,2], class = 0)
link_data <- rbind(df_pos, df_neg)

# STEP 5: Compute structural heuristics
compute_heuristics <- function(graph, df) {
  cn <- sapply(1:nrow(df), function(i) {
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i])))
  })
  jc <- sapply(1:nrow(df), function(i) {
    u <- union(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    if (length(u) == 0) return(0)
    length(intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))) / length(u)
  })
  aa <- sapply(1:nrow(df), function(i) {
    common <- intersect(neighbors(graph, df$from[i]), neighbors(graph, df$to[i]))
    sum(1 / log(degree(graph, common) + 1e-10))
  })
  pa <- sapply(1:nrow(df), function(i) {
    degree(graph, df$from[i]) * degree(graph, df$to[i])
  })
  df$common_neighbors <- cn
  df$jaccard <- jc
  df$adamic_adar <- aa
  df$preferential_attachment <- pa
  return(df)
}

link_data_features <- compute_heuristics(g_train, link_data)

# STEP 6: Extract edge timestamp data and compute temporal features
edge_df <- as_data_frame(g, what = "edges")
edge_df$timestamp <- as.numeric(edge_df$timestamp)

# Frequency and most recent contact per edge
freq_table <- edge_df %>%
  group_by(from, to) %>%
  summarise(freq = n(), last_time = max(timestamp)) %>%
  ungroup()

# STEP 7: Merge temporal features into link_data_features
link_data_features <- left_join(link_data_features, freq_table, by = c("from", "to"))

# Fill missing values for non-edges
link_data_features$freq[is.na(link_data_features$freq)] <- 0
link_data_features$last_time[is.na(link_data_features$last_time)] <- 0

# STEP 8: Train/test split
set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]

# STEP 9: Fit logistic regression with temporal features
model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment +
               freq + last_time,
             data = train, family = "binomial")

summary(model)

# STEP 10: Evaluate performance
pred_probs <- predict(model, newdata = test, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)
conf_matrix <- table(Predicted = pred_class, Actual = test$class)

# Metrics
accuracy <- mean(pred_class == test$class)
TP <- conf_matrix["1", "1"]
FP <- conf_matrix["1", "0"]
FN <- conf_matrix["0", "1"]

precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print results
print(conf_matrix)
cat("Accuracy:", round(accuracy, 3), "\n")
cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")

```

##### Community detection features (e.g., are both nodes in the same community?)

```{r}
# Convert directed training graph to undirected
g_train_undirected <- as.undirected(g_train, mode = "collapse")

# Now run Louvain on the undirected graph
comm <- cluster_louvain(g_train_undirected)

# Get community memberships
membership_vec <- membership(comm)

# Assign community IDs to link_data_features
link_data_features$comm_from <- membership_vec[as.numeric(link_data_features$from)]
link_data_features$comm_to   <- membership_vec[as.numeric(link_data_features$to)]

# Add binary feature: 1 if nodes are in the same community, 0 otherwise
link_data_features$same_community <- ifelse(
  link_data_features$comm_from == link_data_features$comm_to, 1, 0
)


set.seed(123)
train_indices <- sample(1:nrow(link_data_features), size = 0.7 * nrow(link_data_features))
train <- link_data_features[train_indices, ]
test <- link_data_features[-train_indices, ]


model <- glm(class ~ common_neighbors + jaccard + adamic_adar + preferential_attachment +
               same_community,
             data = train, family = "binomial")

summary(model)


```

## Conclusion

*Some concluding words*

## References

-   Sapiezynski, P., Stopczynski, A., Wind, D. K., Leskovec, J., & Lehmann, S. (2019). Interaction data from the Copenhagen Networks Study \[Dataset\]. KONECT – The Koblenz Network Collection. https://networks.skewed.de/net/copenhagen
